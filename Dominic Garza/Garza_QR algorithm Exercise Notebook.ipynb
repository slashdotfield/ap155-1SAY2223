{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93067736",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import numpy.random as ra\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933f516c",
   "metadata": {},
   "source": [
    "# <center> Motivation </center>\n",
    "\n",
    "An infinite set of matrices with the same eigenvalues can be produced, starting from the solution of a single eigenvalue problem. That is, lets start with a matrix $\\mathbf{A}$. The eigenvalue problem consists of finding an eigenvalue $\\lambda$ and a set of eigenvectors $v \\in V(\\mathbf{A})$ such that\n",
    "\\begin{equation}\n",
    "(\\forall v \\in V(\\mathbf{A})): (\\mathbf{A} - \\lambda \\mathbb{1}) v = 0\n",
    "\\end{equation}\n",
    "We can construct a new matrix $\\mathbf{\\tilde{A}}$ with the same eigenvalues by defining its set of eigenvectors $\\tilde{v} \\in V(\\mathbf{\\tilde{A}})$ to be related to $v \\in V(\\mathbf{A})$ by\n",
    "\\begin{equation}\n",
    "(\\exists v \\in V(\\mathbf{A}, \\forall \\tilde{v} \\in V(\\mathbf{\\tilde{A}})): v = \\mathbf{Q} \\tilde{v}\n",
    "\\end{equation}\n",
    "for some invertible matrix $\\mathbf{Q}$. To show this, we begin with a true statement and slowly massage it into another eigenvalue problem with the same eigenvalue $\\lambda$.\n",
    "\\begin{equation}\n",
    "(\\mathbf{A} - \\lambda \\mathbb{1}) v = 0 \\to (\\mathbf{A} - \\lambda) \\mathbb{1}) \\mathbf{Q} \\tilde{v} = 0 \\to (\\mathbf{A} \\mathbf{Q} - \\lambda \\mathbf{Q} ) \\tilde{v} = 0\n",
    "\\end{equation}\n",
    "We note that the above equation, via associativity, reduces to a related eigenvalue problem when we multiply it by $\\mathbf{Q}^{-1}$,\n",
    "\\begin{equation}\n",
    "(\\mathbf{Q}^{-1} \\mathbf{A} \\mathbf{Q} - \\lambda \\mathbb{1} ) \\tilde{v} = 0.\n",
    "\\end{equation}\n",
    "And so, by inspection, we have identified a related matrix $\\mathbf{\\tilde{A}} = \\mathbf{Q}^{-1} \\mathbf{A} \\mathbf{Q}$ with the same eigenvalues as $\\mathbf{A}$, but with a different set of eigenvectors.\n",
    "\n",
    "This transformation is called a **similarity transformation**. Wouldn't it be nice if we are able to find a similarity transformation such that $\\mathbf{\\tilde{A}}$ is an upper triangular matrix? This is called the Schur form of $\\mathbf{A}$, given a special name since one can now read off the eigenvalues of $\\mathbf{A}$ with $\\mathbf{\\tilde{A}}$ - it's just the diagonal elements!\n",
    "___\n",
    "\n",
    "Similarity transformations are dime a dozen. We might want to restrict the set of matrices $\\mathbf{Q}$, which we use to define the transformation - thinking about considerations of stability.\n",
    "\n",
    "One good idea you can have is that the similarity transformation should somehow preserve the size of the eigenvectors. We know of one such set - orthogonal matrices. These matrices are defined by the fact that their transposes are also their own inverse.\n",
    "\\begin{equation}\n",
    "\\mathbf{Q}^T \\mathbf{Q} = \\mathbf{Q}^{-1} \\mathbf{Q} = \\mathbb{1}\n",
    "\\end{equation}\n",
    "It is easy to show their size-preserving property. Consider\n",
    "\\begin{equation}\n",
    "\\tilde{v} = Q^{-1} v\n",
    "\\end{equation}\n",
    "Then the norm of $\\tilde{v}$ is equal to the norm of $v$, as shown here:\n",
    "\\begin{equation}\n",
    "\\tilde{v}^T \\tilde{v} = \\left( Q^{-1} v \\right)^T Q^{-1} v = \\left( Q^T v \\right)^T Q^T v = \\left( v^T Q \\right) Q^T v = v^T \\left( Q^T Q \\right) v = v^T v\n",
    "\\end{equation}\n",
    "This is a usful similarity transformation, since if we wish to go through a set of similarity transformations (and we will), the size of the matrices involved will, in some sense, remain constant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141edc7b",
   "metadata": {},
   "source": [
    "## <center> Gram-Schmidt orthonormalization </center>\n",
    "\n",
    "There is an easy way to construct an $N \\times N$ orthogonal matrix. If we have a set of $N$ orthonomal $N$-vectors, $\\{u_i\\}$, defined by\n",
    "\\begin{equation}\n",
    "u^T_i u_k = \\delta_{i,k},\n",
    "\\end{equation}\n",
    "then an orthogonal matrix can be constructed by using the set $\\{u_i\\}$ as either the column vectors of the matrix,\n",
    "\\begin{equation}\n",
    "Q = [u_1, u_2, \\dots, u_{N-1}, u_N]\n",
    "\\end{equation}\n",
    "or the row vectors of the matrix\n",
    "\\begin{equation}\n",
    "Q = [u_1, u_2, \\dots, u_{N-1}, u_N]^T\n",
    "\\end{equation}\n",
    "___\n",
    "\n",
    "This begs the question: how do we generate set of $N$ orthonormal $N$-vectors? Before answering this, how can we generate a vector $v$ that is orthogonal to another set of orthogonal vectors $\\{w_i\\}$. One idea is to sequentially remove the components of $v$ that is parallel to each of the vectors.\n",
    "That is, we can calculate $v_{i,\\parallel}$,\n",
    "\\begin{equation}\n",
    "\\dfrac{v\\cdot w_i}{|w_i|} \\hat{w_i} = v_{i,\\parallel} \\to \\dfrac{v\\cdot w_i}{w_i \\cdot w_i} w_i = v_{i,\\parallel},\n",
    "\\end{equation}\n",
    "and then remove this from $v$,\n",
    "\\begin{equation}\n",
    "u = v - \\sum_{i} v_{i,\\parallel} = v - \\sum_{i} \\dfrac{v\\cdot w_i}{w_i \\cdot w_i} w_i\n",
    "\\end{equation}\n",
    "We are assured that\n",
    "\\begin{equation}\n",
    "w_i \\cdot u = 0,\n",
    "\\end{equation}\n",
    "since\n",
    "\\begin{equation}\n",
    "w_i \\cdot w_k = \\delta_{i,k}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9dc1b1",
   "metadata": {},
   "source": [
    "In the following, define a function $\\texttt{getorthogonal}$ which takes in as first input a vector $v$ and as second input a set of orthogonal $\\{w_i\\}$, and outputs $u$ which is orthogonal to each of the vectors in $\\{w_i\\}$.\n",
    "\n",
    "A useful function here is $\\texttt{np.copy}$, which copies a matrix to another variable so that mutations on the copied matrix does not affect the original matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67a8eea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getorthogonal(v, w_set):\n",
    "\n",
    "    u = np.copy(v)\n",
    "    for w in w_set:\n",
    "        u -= (np.dot(v,w))/(np.dot(w,w))*w\n",
    "    return u"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1e3f5e",
   "metadata": {},
   "source": [
    "In the following unit test, w_set is a set of orthogonal vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31491c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "N_w = 5\n",
    "N_test = 50\n",
    "w_set = [np.array([1,2,0,0,0,0,0,0,0,0]),np.array([0,0,5,3,0,0,0,0,0,0]),np.array([0,0,0,0,2,9,0,0,0,0]), \\\n",
    "        np.array([0,0,0,0,0,0,3,9,0,0]), np.array([0,0,0,0,0,0,0,0,3,1])]\n",
    "error = 1E-6\n",
    "\n",
    "for _ in range(N_test):\n",
    "    v = ra.rand(N)\n",
    "    u = getorthogonal(v,w_set)\n",
    "    for w in w_set:\n",
    "        assert np.dot(u,w) < error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc33d34a",
   "metadata": {},
   "source": [
    "It would be useful if $\\texttt{getorthogonal}$ can work with an empty set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "700efeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = ra.rand(N)\n",
    "u = getorthogonal(v,[])\n",
    "assert (np.dot(u,v) - np.dot(v,v)) < error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3f9e6b",
   "metadata": {},
   "source": [
    "In the following, define a function $\\texttt{normalize}$ whose input is a set of vectors $\\{w_i\\}$ and whose outputs are vectors $\\{u_i\\}$ with unit length,\n",
    "\\begin{equation}\n",
    "u_i \\cdot u_i = 1\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc23149f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(w_set):\n",
    "\n",
    "    u_set = []\n",
    "    for w in w_set:\n",
    "        u_set.append(w/np.sqrt(np.dot(w,w)))\n",
    "    return u_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208e923c",
   "metadata": {},
   "source": [
    "We modify the previous unit test, using an orthogonal set $\\texttt{wset}$ and test whether the output of normalize is an orthonormal set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36a5a2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_set = [np.array([1,2,0,0,0,0,0,0,0,0]),np.array([0,0,5,3,0,0,0,0,0,0]),np.array([0,0,0,0,2,9,0,0,0,0]), \\\n",
    "        np.array([0,0,0,0,0,0,3,9,0,0]), np.array([0,0,0,0,0,0,0,0,3,1])]\n",
    "error = 1E-6\n",
    "\n",
    "u_set = normalize(w_set)\n",
    "for ui in u_set:\n",
    "    for uk in u_set:\n",
    "        assert abs(np.dot(ui,uk)) < error or abs(1 - np.dot(ui,uk)) < error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094dd39d",
   "metadata": {},
   "source": [
    "We are now ready to do the Gram-Schmidt process. The idea is that if we are given a set of linearly independent vectors $\\{v_i\\}$, we may sequentially produce a set of orthogonal vectors using $\\texttt{getorthogonal}$.\n",
    "\n",
    "That is, we start by selecting one vector $v_1$, and adding that vector into $\\{w_i\\}$. Then select another vector v_2, use $\\texttt{getorthogonal}$ before adding the result to $\\{w_i\\}$. This goes on until we select the last vector in $\\{v_i\\}$. Then we use $\\texttt{normalize}$ to generate an orthonormal set of vectors.\n",
    "\n",
    "Implement this idea in $\\texttt{orthonormalize}$, whose input is a set of linearly independent vectors $\\{v_i\\}$, whose partial output is an orthogonal set of vectors $\\{w_i\\}$ and whose final output is an orthonormal set of vectors $\\{u_i\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ba31250",
   "metadata": {},
   "outputs": [],
   "source": [
    "def orthonormalize(v_set):    \n",
    "    \n",
    "    w_set = [v_set[0]]\n",
    "    N = len(v_set)\n",
    "    for i in range(1,N) :\n",
    "        w_set.append(getorthogonal(v_set[1],w_set))\n",
    "    u_set = normalize(w_set)\n",
    "    return u_set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031dde95",
   "metadata": {},
   "source": [
    "In the following, we produce a random set of linearly independent vectors, and then test if the output of $\\texttt{orthonormalize}$ is an orthonormal set of vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45010a84",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ui \u001b[38;5;129;01min\u001b[39;00m u_set:\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m uk \u001b[38;5;129;01min\u001b[39;00m u_set:\n\u001b[1;32m---> 10\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39mdot(ui,uk) \u001b[38;5;241m<\u001b[39m error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(ui,uk)) \u001b[38;5;241m<\u001b[39m error\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "N = 10\n",
    "error = 1E-6\n",
    "v_set = []\n",
    "for _ in range(N):\n",
    "    v_set.append(ra.rand(N))\n",
    "\n",
    "u_set = orthonormalize(v_set)\n",
    "for ui in u_set:\n",
    "    for uk in u_set:\n",
    "        assert np.dot(ui,uk) < error or abs(1 - np.dot(ui,uk)) < error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efd1cf1",
   "metadata": {},
   "source": [
    "## <center> Calculating $\\mathbf{Q}$ </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bb1b05",
   "metadata": {},
   "source": [
    "The technical details of the QR algorithm is beyond our reach. However, one can grasp general ideas from what we already know. The following equation\n",
    "\\begin{equation}\n",
    "\\tilde{A} = Q^T \\tilde{A} Q\n",
    "\\end{equation}\n",
    "can be understood as a relaxation problem, since it is of the form\n",
    "\\begin{equation}\n",
    "x = f(x), \\qquad x^{(n+1)} = \\alpha f(x^{(n)}) - (1-\\alpha) x^{(n)}\n",
    "\\end{equation}\n",
    "Thus, a sequence can be created of approximation of $\\mathbf{\\tilde{A}}$ via the following recursion,\n",
    "\\begin{equation}\n",
    "\\tilde{A}^{(n+1)} = \\alpha \\left( Q^T \\tilde{A}^{(n)} Q \\right) - (1-\\alpha) \\tilde{A}^{(n)}\n",
    "\\end{equation}\n",
    "In the language of Chapter 6 of Newmann, the QR algorithm can be understood as simply an overrelaxed root finding problem, choosing $\\alpha = 1$.\n",
    "\\begin{equation}\n",
    "\\tilde{A}^{(n+1)} = Q^T \\tilde{A}^{(n)} Q\n",
    "\\end{equation}\n",
    "There's a lot of choices for $Q$, but we want to select $Q$ such that the solution $\\tilde{A}$ to \n",
    "\\begin{equation}\n",
    "\\tilde{A} = Q^T \\tilde{A} Q\n",
    "\\end{equation}\n",
    "is an upper triangular matrix - aka, the Schur form of our seed matrix $\\tilde{A}^{(0)} = A$. Apparently, one such choice is to construct $Q$ from the set of orthonormal vectors that arise by applying the Gram-Schmidt process on the column vectors of $\\tilde{A}$.\n",
    "\n",
    "In the language of the relaxation process, we may think of $Q$ as a function on $\\tilde{A}$, such that\n",
    "\\begin{equation}\n",
    "\\tilde{A}^{(n+1)} = Q^T\\left( \\tilde{A}^{(n)} \\right) \\tilde{A}^{(n)} Q \\left( \\tilde{A}^{(n)} \\right)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5019343",
   "metadata": {},
   "source": [
    "In the following function $\\texttt{getQ}$, it should have as input a matrix $\\mathbf{A}$, extract its column vectors and use $\\texttt{orthonormalize}$ to generate $\\mathbf{Q}$ whose column vectors are the outputted orthonormal set of vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bba7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getQ(A):\n",
    "    Q = np.transpose(A) #extract column vectors of A\n",
    "    Q = orthonormalize(Q)\n",
    "    Q = np.transpose(Q)\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906626fa",
   "metadata": {},
   "source": [
    "In the following unit test, we check whether the output of $\\texttt{getQ}$ is a orthogonal matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2822dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 20\n",
    "N_test = 500\n",
    "error = 1E-10\n",
    "for _ in range(N_test):\n",
    "    A = ra.rand(N,N)\n",
    "    Q = getQ(A)\n",
    "    QT = np.transpose(Q)\n",
    "    assert la.norm(np.dot(QT,Q) - np.identity(N)) < error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61d9134",
   "metadata": {},
   "source": [
    "In the following unit test, we check whether $Q^T A$ results in an upper triangular matrix. We use $\\texttt{np.tril(A,-1)}$ to get the lower triangular part of $A$ excluding the diagonal, which should be filled with zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d45249e",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 20\n",
    "N_test = 500\n",
    "error = 1E-10\n",
    "for _ in range(N_test):\n",
    "    A = ra.rand(N,N)\n",
    "    Q = getQ(A)\n",
    "    QT = np.transpose(Q)\n",
    "    R = np.dot(QT,A)\n",
    "    assert la.norm(np.tril(R,-1)) < error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7ea7dd",
   "metadata": {},
   "source": [
    "## <center> Calculating $A^{(n)}$ and $Q^{(n)}$ </center>\n",
    "\n",
    "Now we can start iterating what is called thje $QR$ algorithm (ignore the $R$, there's a least square optimization algorithm somewhere in here as well, which we shall be ignoring).\n",
    "\n",
    "There are two things we should be keeping track of. The $n$th similar matrix $\\mathbf{A}^{(n)}$ (which hopefully converges to the Schur form of $\\mathbf{A}^{(0)} = \\mathbf{A}$), and the total similarity transformation $\\mathbf{Q}^{(n)}$ starting from $\\mathbb{1}$.\n",
    "\n",
    "That is, we begin with the pair\n",
    "\\begin{equation}\n",
    "\\left( \\mathbf{A}^{(0)}, \\mathbf{Q}^{(0)} \\right) = \\left(\\mathbf{A}, \\mathbb{1} \\right)\n",
    "\\end{equation}\n",
    "and then iterate with\n",
    "\\begin{equation}\n",
    "\\left( \\mathbf{A}^{(n)}, \\mathbf{Q}^{(n)} \\right) = \\left( Q^T_{n-1} \\mathbf{A}^{(n-1)} Q_{n-1}, Q_{n-1} \\mathbf{Q}^{(n-1)}\\right)\n",
    "\\end{equation}\n",
    "where\n",
    "\\begin{equation}\n",
    "Q_{n-1} = Q\\left(\\mathbf{A}^{(n-1)}\\right)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c88b7d",
   "metadata": {},
   "source": [
    "In the following function $\\texttt{updateAQ}$, let its inputs be the $n$th similar matrix and the corresponding similarity transformation, and updates via the above scheme where\n",
    "\\begin{equation}\n",
    "\\mathbf{A}^{(n)} = Q^T_{n-1} \\mathbf{A}^{(n-1)} Q_{n-1}\n",
    "\\end{equation}\n",
    "and\n",
    "\\begin{equation}\n",
    "\\mathbf{Q}^{(n)} = Q_{n-1} \\mathbf{Q}^{(n-1)}\n",
    "\\end{equation}\n",
    "where\n",
    "\\begin{equation}\n",
    "Q_{n-1} = Q\\left(\\mathbf{A}^{(n-1)}\\right)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd440c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateAQ(Anm1,Qnm1):\n",
    "\n",
    "    for n in range(len(A)):\n",
    "        Qn_1 = np.dot(Q,A**(n-1))\n",
    "        An = np.dot(np.dot(np.transpose(Qn_1),A**(n-1)),Qn_1)\n",
    "        An = A**n\n",
    "        Qn = np.dot(Qn_1,Q**(n-1))\n",
    "        Qn = Q**n\n",
    "    return An,Qn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d75e632",
   "metadata": {},
   "source": [
    "The following code should show that the QR algorithm quickly converges to the Schur form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d6181d",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 30\n",
    "iterlen = 10\n",
    "norm_list = []\n",
    "A = np.array([[1.,2.],[3.,5.]])\n",
    "Q = np.identity(2)\n",
    "\n",
    "norm_list.append(la.norm(np.tril(A,-1)))\n",
    "for _ in range(iterlen):\n",
    "    A,Q = updateAQ(A,Q)\n",
    "    norm_list.append(la.norm(np.tril(A,-1)))\n",
    "plt.plot(norm_list)\n",
    "plt.yscale('log')\n",
    "plt.show()\n",
    "print(norm_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c16ce3c",
   "metadata": {},
   "source": [
    "## <center> The eigenvalue problem </center>\n",
    "\n",
    "Let us now combine everything. In the following code, we shall iterate the QR algorithm in the function $\\texttt{solveeigen}$, including an optional argument which sets an upper bound for the norm of the lower triangular part of $\\mathbf{A}^{(n)}$ and a maximum number of iterations for the QR algorithm. The function should not mutate the input matrix - use $\\texttt{np.copy}$. The output should be a set of eigenvalues of $\\mathbf{A}$.\n",
    "\n",
    "If the QR algorithm does not converge, it must return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0e95db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solveeigen(A,error = 1E-9, maxiter = 10000):\n",
    "\n",
    "    N = len(A)\n",
    "    An = np.copy(A)\n",
    "    Qn = np.identity(N)\n",
    "    \n",
    "    for _ in range(maxiter):\n",
    "        An,Qn = updateAQ(An,Qn)\n",
    "        la.norm(np.tril(An,-1))\n",
    "        \n",
    "        if la.norm(np.tril(An,-1)) < error:\n",
    "            eigenvalues = []\n",
    "            for i in range(N):\n",
    "                eigenvalues.append(An[i,i])\n",
    "        \n",
    "            return eigenvalues\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6085b490",
   "metadata": {},
   "source": [
    "In the following unit test, we generate a matrix whose eigenvalues are known via a similarity transformation. We then get the eigenvalues using $\\texttt{solveeigen}$ above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a711fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate matrix whose eigenvalues are known\n",
    "N = 10\n",
    "eigvals = ra.rand(N)\n",
    "A = np.diag(eigvals)\n",
    "\n",
    "## generate a similarity matrix\n",
    "V = ra.rand(N,N)\n",
    "Q = getQ(V)\n",
    "QT = np.transpose(Q)\n",
    "\n",
    "## similarity transformation\n",
    "A = np.dot(np.dot(QT,A),Q)\n",
    "\n",
    "## solve numerical eigenvalues\n",
    "numeigvals = solveeigen(A)\n",
    "assert la.norm(np.sort(numeigvals) - np.sort(eigvals)) < error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfdf7bd",
   "metadata": {},
   "source": [
    "## <center> What about the eigenvectors </center>\n",
    "\n",
    "The eigenvectors of the Schur form of $\\mathbf{A}$ is easy to solve, because the matrix is of upper triangular form. This is achievable via back propagation. Then, one can use the total similarity transformation $Q^{(n)}$ to calculate the eigenvectors of $\\mathbf{A}$.\n",
    "\n",
    "This is left as an exercise to the masipag na reader."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
